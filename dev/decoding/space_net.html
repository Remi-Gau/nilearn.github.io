
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta property="og:title" content="2.4. SpaceNet: decoding with spatial structure for better maps" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://nilearn.github.io/decoding/space_net.html" />
  <meta property="og:site_name" content="Nilearn" />
  <meta property="og:description" content="The SpaceNet decoder: nilearn.decoding.SpaceNetRegressor and nilearn.decoding.SpaceNetClassifier implements spatial penalties which improve brain decoding power as well as decoder maps: penalty=”tv..." />
  <meta property="og:image" content="https://nilearn.github.io/_images/sphx_glr_plot_oasis_vbm_space_net_002.png" />
  <meta property="og:image:alt" content="Nilearn" />
  
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2.5. Searchlight : finding voxels containing information" href="searchlight.html" />
    <link rel="prev" title="2.3. FREM: fast ensembling of regularized models for robust decoding" href="frem.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../index.html">
      <img src="../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="searchlight.html" title="2.5. Searchlight : finding voxels containing information"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="frem.html" title="2.3. FREM: fast ensembling of regularized models for robust decoding"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../authors.html">About</a>|&nbsp;</li>
<li><a href="../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="index.html" accesskey="U"><span class="section-number">2. </span>Decoding and MVPA: predicting from brain images</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>

<div class="devel-alert-banner">
This is documentation for the <em>unstable development version</em> of Nilearn,
the current stable version is available <a href="https://nilearn.github.io/stable/index.html">here</a>.
</div>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="spacenet-decoding-with-spatial-structure-for-better-maps">
<span id="space-net"></span><h1><span class="section-number">2.4. </span>SpaceNet: decoding with spatial structure for better maps<a class="headerlink" href="#spacenet-decoding-with-spatial-structure-for-better-maps" title="Permalink to this headline">¶</a></h1>
<section id="the-spacenet-decoder">
<h2><span class="section-number">2.4.1. </span>The SpaceNet decoder<a class="headerlink" href="#the-spacenet-decoder" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../modules/generated/nilearn.decoding.SpaceNetRegressor.html#nilearn.decoding.SpaceNetRegressor" title="nilearn.decoding.SpaceNetRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">nilearn.decoding.SpaceNetRegressor</span></code></a> and <a class="reference internal" href="../modules/generated/nilearn.decoding.SpaceNetClassifier.html#nilearn.decoding.SpaceNetClassifier" title="nilearn.decoding.SpaceNetClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">nilearn.decoding.SpaceNetClassifier</span></code></a>
implements spatial penalties which improve brain decoding power as well as decoder maps:</p>
<ul class="simple">
<li><p>penalty=”tvl1”: priors inspired from TV (Total Variation) [Michel <em>et al.</em><a class="footnote-reference brackets" href="#footcite-michel-inria-00563468" id="id1">1</a>], TV-L1 [Baldassarre <em>et al.</em><a class="footnote-reference brackets" href="#footcite-baldassarre2012" id="id2">2</a>], [Gramfort <em>et al.</em><a class="footnote-reference brackets" href="#footcite-gramfort-hal-00839984" id="id3">3</a>].</p></li>
<li><p>penalty=”graph-net”: GraphNet prior [Grosenick <em>et al.</em><a class="footnote-reference brackets" href="#footcite-grosenick2013304" id="id4">4</a>].</p></li>
</ul>
<p>These regularize <a class="reference internal" href="../glossary.html#term-classification"><span class="xref std std-term">classification</span></a> and <a class="reference internal" href="../glossary.html#term-regression"><span class="xref std std-term">regression</span></a>
problems in brain imaging. The results are brain maps which are both
sparse (i.e regression coefficients are zero everywhere, except at
predictive <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxels</span></a>) and structured (blobby). The superiority of TV-L1
over methods without structured priors like the Lasso, <a class="reference internal" href="../glossary.html#term-SVM"><span class="xref std std-term">SVM</span></a>, <a class="reference internal" href="../glossary.html#term-ANOVA"><span class="xref std std-term">ANOVA</span></a>,
Ridge, etc. for yielding more interpretable maps and improved
prediction scores is now well established [Baldassarre <em>et al.</em><a class="footnote-reference brackets" href="#footcite-baldassarre2012" id="id5">2</a>], [Gramfort <em>et al.</em><a class="footnote-reference brackets" href="#footcite-gramfort-hal-00839984" id="id6">3</a>], [Grosenick <em>et al.</em><a class="footnote-reference brackets" href="#footcite-grosenick2013304" id="id7">4</a>].</p>
<p>Note that TV-L1 prior leads to a difficult optimization problem, and so can be slow to run.
Under the hood, a few heuristics are used to make things a bit faster. These include:</p>
<ul class="simple">
<li><p>Feature preprocessing, where an F-test is used to eliminate
non-predictive <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxels</span></a>, thus reducing the size of the brain
mask in a principled way.</p></li>
<li><p>Continuation is used along the regularization path, where the
solution of the optimization problem for a given value of the
regularization parameter <cite>alpha</cite> is used as initialization
for the next regularization (smaller) value on the regularization
grid.</p></li>
</ul>
<p><strong>Implementation:</strong> See [Dohmatob <em>et al.</em><a class="footnote-reference brackets" href="#footcite-dohmatob-hal-01147731" id="id8">5</a>] and [Dohmatob <em>et al.</em><a class="footnote-reference brackets" href="#footcite-dohmatob-hal-00991743" id="id9">6</a>] for technical details regarding the implementation of SpaceNet.</p>
</section>
<section id="related-example">
<h2><span class="section-number">2.4.2. </span>Related example<a class="headerlink" href="#related-example" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm_space_net.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-space-net-py"><span class="std std-ref">Age prediction on OASIS dataset with SpaceNet</span></a>.</p>
<figure class="align-default">
<img alt="../_images/sphx_glr_plot_oasis_vbm_space_net_002.png" src="../_images/sphx_glr_plot_oasis_vbm_space_net_002.png" />
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Empirical comparisons using this method have been removed from
documentation in version 0.7 to keep its computational cost low. You can
easily try SpaceNet instead of FREM in <a class="reference internal" href="../auto_examples/02_decoding/plot_mixed_gambles_frem.html#sphx-glr-auto-examples-02-decoding-plot-mixed-gambles-frem-py"><span class="std std-ref">mixed gambles study</span></a> or <a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_frem.html#sphx-glr-auto-examples-02-decoding-plot-haxby-frem-py"><span class="std std-ref">Haxby study</span></a>.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="frem.html#frem"><span class="std std-ref">FREM</span></a>, a pipeline ensembling many models that yields very
good decoding performance at a lower computational cost.</p>
</div>
</section>
<section id="references">
<h2><span class="section-number">2.4.3. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="id10"><dl class="footnote brackets">
<dt class="label" id="footcite-michel-inria-00563468"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Vincent Michel, Alexandre Gramfort, Gaël Varoquaux, Evelyn Eger, and Bertrand Thirion. Total variation regularization for fMRI-based prediction of behaviour. <em>IEEE Transactions on Medical Imaging</em>, 30(7):1328 – 1340, February 2011. URL: <a class="reference external" href="https://hal.inria.fr/inria-00563468">https://hal.inria.fr/inria-00563468</a>, <a class="reference external" href="https://doi.org/10.1109/TMI.2011.2113378">doi:10.1109/TMI.2011.2113378</a>.</p>
</dd>
<dt class="label" id="footcite-baldassarre2012"><span class="brackets">2</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id5">2</a>)</span></dt>
<dd><p>Luca Baldassarre, Janaina Mourao-Miranda, and Massimiliano Pontil. Structured sparsity models for brain decoding from fmri data. In <em>2012 Second International Workshop on Pattern Recognition in NeuroImaging</em>, volume, 5–8. 2012. URL: <a class="reference external" href="http://www0.cs.ucl.ac.uk/staff/M.Pontil/reading/neurosparse_prni.pdf">http://www0.cs.ucl.ac.uk/staff/M.Pontil/reading/neurosparse_prni.pdf</a>, <a class="reference external" href="https://doi.org/10.1109/PRNI.2012.31">doi:10.1109/PRNI.2012.31</a>.</p>
</dd>
<dt class="label" id="footcite-gramfort-hal-00839984"><span class="brackets">3</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id6">2</a>)</span></dt>
<dd><p>Alexandre Gramfort, Bertrand Thirion, and Gaël Varoquaux. Identifying predictive regions from fMRI with TV-L1 prior. In <em>Pattern Recognition in Neuroimaging (PRNI)</em>. Philadelphia, United States, June 2013. IEEE. URL: <a class="reference external" href="https://hal.inria.fr/hal-00839984">https://hal.inria.fr/hal-00839984</a>.</p>
</dd>
<dt class="label" id="footcite-grosenick2013304"><span class="brackets">4</span><span class="fn-backref">(<a href="#id4">1</a>,<a href="#id7">2</a>)</span></dt>
<dd><p>Logan Grosenick, Brad Klingenberg, Kiefer Katovich, Brian Knutson, and Jonathan E. Taylor. Interpretable whole-brain prediction analysis with graphnet. <em>NeuroImage</em>, 72:304–321, 2013. URL: <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811912012487">https://www.sciencedirect.com/science/article/pii/S1053811912012487</a>, <a class="reference external" href="https://doi.org/https://doi.org/10.1016/j.neuroimage.2012.12.062">doi:https://doi.org/10.1016/j.neuroimage.2012.12.062</a>.</p>
</dd>
<dt class="label" id="footcite-dohmatob-hal-01147731"><span class="brackets"><a class="fn-backref" href="#id8">5</a></span></dt>
<dd><p>Elvis Dohmatob, Michael Eickenberg, Bertrand Thirion, and Gaël Varoquaux. Speeding-up model-selection in GraphNet via early-stopping and univariate feature-screening. In <em>PRNI</em>. Stanford, United States, June 2015. URL: <a class="reference external" href="https://hal.inria.fr/hal-01147731">https://hal.inria.fr/hal-01147731</a>.</p>
</dd>
<dt class="label" id="footcite-dohmatob-hal-00991743"><span class="brackets"><a class="fn-backref" href="#id9">6</a></span></dt>
<dd><p>Elvis Dohmatob, Alexandre Gramfort, Bertrand Thirion, and Gaël Varoquaux. Benchmarking solvers for TV-l1 least-squares and logistic regression in brain imaging. In <em>PRNI 2014 - 4th International Workshop on Pattern Recognition in NeuroImaging</em>. Tübingen, Germany, June 2014. IEEE. URL: <a class="reference external" href="https://hal.inria.fr/hal-00991743">https://hal.inria.fr/hal-00991743</a>.</p>
</dd>
</dl>
</p>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">2.4. SpaceNet: decoding with spatial structure for better maps</a><ul>
<li><a class="reference internal" href="#the-spacenet-decoder">2.4.1. The SpaceNet decoder</a></li>
<li><a class="reference internal" href="#related-example">2.4.2. Related example</a></li>
<li><a class="reference internal" href="#references">2.4.3. References</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="frem.html"
                        title="previous chapter"><span class="section-number">2.3. </span>FREM: fast ensembling of regularized models for robust decoding</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="searchlight.html"
                        title="next chapter"><span class="section-number">2.5. </span>Searchlight : finding voxels containing information</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.2.0.
        <span style="padding-left: 5ex;">
          <a href="../_sources/decoding/space_net.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>