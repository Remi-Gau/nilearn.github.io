{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Surface-based dataset first and second level analysis of a dataset\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>This example is adapted from\n    `sphx_glr_auto_examples_07_advanced_plot_surface_bids_analysis.py`. # noqa\n    to show how to use the new tentative API for surface images in nilearn.\n\n    This functionality is provided\n    by the :mod:`nilearn.experimental.surface` module.\n\n    It is still incomplete and subject to change without a deprecation cycle.\n\n    Please participate in the discussion on GitHub!</p></div>\n\nFull step-by-step example of fitting a :term:`GLM`\n(first and second level analysis) in a 10-subjects dataset\nand visualizing the results.\n\nMore specifically:\n\n#. Download an :term:`fMRI` :term:`BIDS` dataset\n   with two language conditions to contrast.\n\n#. Project the data to a standard mesh, fsaverage5,\n   also known as the Freesurfer template :term:`mesh`\n   downsampled to about 10k nodes per hemisphere.\n\n#. Run the first level model objects.\n\n#. Fit a second level model on the fitted first level models.\n\nNotice that in this case the preprocessed :term:`bold<BOLD>` images\nwere already normalized to the same :term:`MNI` space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch example :term:`BIDS` dataset\nWe download a simplified :term:`BIDS` dataset\nmade available for illustrative purposes.\nIt contains only the necessary information\nto run a statistical analysis using Nilearn.\nThe raw data subject folders only contain bold.json and events.tsv files,\nwhile the derivatives folder includes the preprocessed files preproc.nii\nand the confounds.tsv files.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_language_localizer_demo_dataset\n\ndata = fetch_language_localizer_demo_dataset(legacy_output=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the location of the dataset on disk.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(data.data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtain automatically FirstLevelModel objects and fit arguments\nFrom the dataset directory we automatically obtain\nthe FirstLevelModel objects\nwith their subject_id filled from the :term:`BIDS` dataset.\nMoreover, we obtain for each model\na dictionary with run_imgs, events and confounder regressors\nsince in this case a confounds.tsv file is available\nin the :term:`BIDS` dataset.\nTo get the first level models we only have to specify the dataset directory\nand the task_label as specified in the file names.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm.first_level import first_level_from_bids\n\ntask_label = \"languagelocalizer\"\nmodels, run_imgs, events, confounds = first_level_from_bids(\n    data.data_dir,\n    task_label,\n    img_filters=[(\"desc\", \"preproc\")],\n    hrf_model=\"glover + derivative\",\n    n_jobs=2,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Project :term:`fMRI` data to the surface and compute GLM and contrasts\n\nThe projection function simply takes the :term:`fMRI` data and the mesh.\nNote that those correspond spatially, as they are both in :term:`MNI` space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nfrom nilearn import surface\nfrom nilearn.experimental.surface import SurfaceImage, load_fsaverage\n\nfsaverage5 = load_fsaverage()\n\n# Empty lists in which we are going to store activation values.\nz_scores_left = []\nz_scores_right = []\nfor first_level_glm, fmri_img, confound, event in zip(\n    models, run_imgs, confounds, events\n):\n    print(f\"Running GLM on {Path(fmri_img[0]).relative_to(data.data_dir)}\")\n\n    texture_left = surface.vol_to_surf(\n        fmri_img[0], fsaverage5[\"pial\"].parts[\"left\"]\n    )\n    texture_right = surface.vol_to_surf(\n        fmri_img[0], fsaverage5[\"pial\"].parts[\"right\"]\n    )\n    image = SurfaceImage(\n        mesh=fsaverage5[\"pial\"],\n        data={\n            \"left\": texture_left.T,\n            \"right\": texture_right.T,\n        },\n    )\n\n    # Fit GLM.\n    first_level_glm.fit(run_imgs=image, events=event[0], confounds=confound[0])\n\n    # Contrast specification\n    design_matrix = first_level_glm.design_matrices_[0]\n    contrast_values = (design_matrix.columns == \"language\") * 1.0 - (\n        design_matrix.columns == \"string\"\n    )\n    z_scores = first_level_glm.compute_contrast(contrast_values, stat_type=\"t\")\n    z_scores_left.append(z_scores.data.parts[\"left\"])\n    z_scores_right.append(z_scores.data.parts[\"right\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Group study\n\nIndividual activation maps have been accumulated\nin the ``z_score_left`` and ``z_scores_right`` lists respectively.\nWe can now use them in a group study (one-sample study).\n\nPrepare figure for concurrent plot of individual maps\ncompute population-level maps for left and right hemisphere\nWe directly do that on the value arrays.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom scipy.stats import norm, ttest_1samp\n\n_, pval_left = ttest_1samp(np.array(z_scores_left), 0)\n_, pval_right = ttest_1samp(np.array(z_scores_right), 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What we have so far are p-values: we convert them to z-values for plotting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_val_left = norm.isf(pval_left)\nz_val_right = norm.isf(pval_right)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the resulting maps, at first on the left hemisphere.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.experimental.plotting import plot_surf_stat_map\nfrom nilearn.experimental.surface import load_fsaverage_data\nfrom nilearn.plotting import show\n\nfsaverage_data = load_fsaverage_data(data_type=\"sulcal\")\n\nfor hemi, stat_map in zip([\"left\", \"right\"], [z_val_left, z_val_right]):\n    plot_surf_stat_map(\n        surf_mesh=fsaverage5[\"inflated\"],\n        stat_map=stat_map,\n        hemi=hemi,\n        title=f\"(language-string), {hemi} hemisphere\",\n        colorbar=True,\n        threshold=3.0,\n        bg_map=fsaverage_data,\n    )\n\nshow()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}