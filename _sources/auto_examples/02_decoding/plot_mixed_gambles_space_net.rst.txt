.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_02_decoding_plot_mixed_gambles_space_net.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_02_decoding_plot_mixed_gambles_space_net.py:


SpaceNet on Jimura et al "mixed gambles" dataset.
==================================================

The segmenting power of SpaceNet is quite visible here.

See also the SpaceNet documentation: :ref:`space_net`.


.. code-block:: default

    # author: DOHMATOB Elvis Dopgima,
    #         GRAMFORT Alexandre









Load the data from the Jimura mixed-gamble experiment
------------------------------------------------------


.. code-block:: default

    from nilearn.datasets import fetch_mixed_gambles
    data = fetch_mixed_gambles(n_subjects=16)

    zmap_filenames = data.zmaps
    behavioral_target = data.gain
    mask_filename = data.mask_img









Fit TV-L1
----------
Here we're using the regressor object given that the task is to predict a
continuous variable, the gain of the gamble.


.. code-block:: default

    from nilearn.decoding import SpaceNetRegressor
    decoder = SpaceNetRegressor(mask=mask_filename, penalty="tv-l1",
                                eps=1e-1,  # prefer large alphas
                                memory="nilearn_cache")

    decoder.fit(zmap_filenames, behavioral_target)

    # Visualize TV-L1 weights
    # ------------------------
    from nilearn.plotting import plot_stat_map, show
    plot_stat_map(decoder.coef_img_, title="tv-l1", display_mode="yz",
                  cut_coords=[20, -2])





.. image:: /auto_examples/02_decoding/images/sphx_glr_plot_mixed_gambles_space_net_001.png
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [NiftiMasker.fit] Loading data from None
    [NiftiMasker.fit] Resampling mask
    /mnt/c/Users/kshit/workspace/nilearn-org/nilearn-repo/kchawla-pi/nilearn/nilearn/_utils/cache_mixin.py:296: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.
      warnings.warn("memory_level is currently set to 0 but "
    [NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(
    shape=(40, 48, 34, 768),
    affine=array([[  -4.,    0.,    0.,   78.],
           [   0.,    4.,    0., -112.],
           [   0.,    0.,    4.,  -50.],
           [   0.,    0.,    0.,    1.]])
    )
    [NiftiMasker.transform_single_imgs] Extracting region signals
    [NiftiMasker.transform_single_imgs] Cleaning extracted signals
    /mnt/c/Users/kshit/workspace/nilearn-org/nilearn-repo/kchawla-pi/nilearn/nilearn/input_data/nifti_masker.py:405: UserWarning: Persisting input arguments took 6.65s to run.
    If this happens often in your code, it can cause performance problems 
    (results will be correct in all cases). 
    The reason for this is probably some large input arguments for a wrapped
     function (e.g. large strings).
    THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
     example so that they can fix the problem.
      dtype=self.dtype
    /mnt/c/Users/kshit/workspace/nilearn-org/nilearn-repo/kchawla-pi/nilearn/nilearn/decoding/space_net.py:834: UserWarning: Brain mask is bigger than the volume of a standard human brain. This object is probably not tuned to be used on such data.
      self.screening_percentile, self.mask_img_, verbose=self.verbose)
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    ....[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.0min remaining:    0.0s
    .............................................[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  9.1min finished
    Time Elapsed: 572.973 seconds, 9 minutes.

    <nilearn.plotting.displays.YZSlicer object at 0x7f5e9618bc10>



Fit Graph-Net
--------------


.. code-block:: default

    decoder = SpaceNetRegressor(mask=mask_filename, penalty="graph-net",
                                eps=1e-1,  # prefer large alphas
                                memory="nilearn_cache")
    decoder.fit(zmap_filenames, behavioral_target)

    # Visualize Graph-Net weights
    # ----------------------------
    plot_stat_map(decoder.coef_img_, title="graph-net", display_mode="yz",
                  cut_coords=[20, -2])

    show()



.. image:: /auto_examples/02_decoding/images/sphx_glr_plot_mixed_gambles_space_net_002.png
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [NiftiMasker.fit] Loading data from None
    [NiftiMasker.fit] Resampling mask
    /mnt/c/Users/kshit/workspace/nilearn-org/nilearn-repo/kchawla-pi/nilearn/nilearn/_utils/cache_mixin.py:296: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.
      warnings.warn("memory_level is currently set to 0 but "
    [NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(
    shape=(40, 48, 34, 768),
    affine=array([[  -4.,    0.,    0.,   78.],
           [   0.,    4.,    0., -112.],
           [   0.,    0.,    4.,  -50.],
           [   0.,    0.,    0.,    1.]])
    )
    [NiftiMasker.transform_single_imgs] Extracting region signals
    [NiftiMasker.transform_single_imgs] Cleaning extracted signals
    /mnt/c/Users/kshit/workspace/nilearn-org/nilearn-repo/kchawla-pi/nilearn/nilearn/input_data/nifti_masker.py:405: UserWarning: Persisting input arguments took 6.78s to run.
    If this happens often in your code, it can cause performance problems 
    (results will be correct in all cases). 
    The reason for this is probably some large input arguments for a wrapped
     function (e.g. large strings).
    THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
     example so that they can fix the problem.
      dtype=self.dtype
    /mnt/c/Users/kshit/workspace/nilearn-org/nilearn-repo/kchawla-pi/nilearn/nilearn/decoding/space_net.py:834: UserWarning: Brain mask is bigger than the volume of a standard human brain. This object is probably not tuned to be used on such data.
      self.screening_percentile, self.mask_img_, verbose=self.verbose)
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    .........[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.5s remaining:    0.0s
    ...............................................................[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.9min finished
    Time Elapsed: 146.98 seconds, 2 minutes.





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 12 minutes  7.769 seconds)


.. _sphx_glr_download_auto_examples_02_decoding_plot_mixed_gambles_space_net.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_mixed_gambles_space_net.py <plot_mixed_gambles_space_net.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_mixed_gambles_space_net.ipynb <plot_mixed_gambles_space_net.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
