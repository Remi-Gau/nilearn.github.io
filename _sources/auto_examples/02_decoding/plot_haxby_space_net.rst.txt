.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_02_decoding_plot_haxby_space_net.py>` to download the full example code or to run this example in your browser via Binder
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_02_decoding_plot_haxby_space_net.py:


Decoding with SpaceNet: face vs house object recognition
=========================================================

Here is a simple example of decoding with a SpaceNet prior (i.e Graph-Net,
TV-l1, etc.), reproducing the Haxby 2001 study on a face vs house
discrimination task.

See also the SpaceNet documentation: :ref:`space_net`.

Load the Haxby dataset
------------------------


.. code-block:: default

    from nilearn.datasets import fetch_haxby
    data_files = fetch_haxby()

    # Load behavioral data
    import pandas as pd
    behavioral = pd.read_csv(data_files.session_target[0], sep=" ")

    # Restrict to face and house conditions
    conditions = behavioral['labels']
    condition_mask = conditions.isin(['face', 'house'])

    # Split data into train and test samples, using the chunks
    condition_mask_train = (condition_mask) & (behavioral['chunks'] <= 6)
    condition_mask_test = (condition_mask) & (behavioral['chunks'] > 6)

    # Apply this sample mask to X (fMRI data) and y (behavioral labels)
    # Because the data is in one single large 4D image, we need to use
    # index_img to do the split easily
    from nilearn.image import index_img
    func_filenames = data_files.func[0]
    X_train = index_img(func_filenames, condition_mask_train)
    X_test = index_img(func_filenames, condition_mask_test)
    y_train = conditions[condition_mask_train]
    y_test = conditions[condition_mask_test]

    # Compute the mean epi to be used for the background of the plotting
    from nilearn.image import mean_img
    background_img = mean_img(func_filenames)








Fit SpaceNet with a Graph-Net penalty
--------------------------------------


.. code-block:: default

    from nilearn.decoding import SpaceNetClassifier

    # Fit model on train data and predict on test data
    decoder = SpaceNetClassifier(memory="nilearn_cache", penalty='graph-net')
    decoder.fit(X_train, y_train)
    y_pred = decoder.predict(X_test)
    accuracy = (y_pred == y_test).mean() * 100.
    print("Graph-net classification accuracy : %g%%" % accuracy)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [NiftiMasker.fit] Loading data from Nifti1Image(
    shape=(40, 64, 64, 126),
    affine=array([[  -3.5  ,    0.   ,    0.   ,   68.25 ],
           [   0.   ,    3.75 ,    0.   , -118.125],
           [   0.   ,    0.   ,    3.75 , -118.125],
           [
    [NiftiMasker.fit] Computing the mask
    /home/emdupre/Desktop/open_source/nilearn/nilearn/_utils/cache_mixin.py:296: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.
      warnings.warn("memory_level is currently set to 0 but "
    [NiftiMasker.fit] Resampling mask
    [NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(
    shape=(40, 64, 64, 126),
    affine=array([[  -3.5  ,    0.   ,    0.   ,   68.25 ],
           [   0.   ,    3.75 ,    0.   , -118.125],
           [   0.   ,    0.   ,    3.75 , -118.125],
           [
    [NiftiMasker.transform_single_imgs] Extracting region signals
    [NiftiMasker.transform_single_imgs] Cleaning extracted signals
    /home/emdupre/Desktop/open_source/nilearn/nilearn/decoding/space_net.py:834: UserWarning: Brain mask is bigger than the volume of a standard human brain. This object is probably not tuned to be used on such data.
      self.screening_percentile, self.mask_img_, verbose=self.verbose)
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    .........[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s remaining:    0.0s
    .............................................................[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.3min finished
    Time Elapsed: 80.4599 seconds, 1 minutes.
    [NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(
    shape=(40, 64, 64, 90),
    affine=array([[  -3.5  ,    0.   ,    0.   ,   68.25 ],
           [   0.   ,    3.75 ,    0.   , -118.125],
           [   0.   ,    0.   ,    3.75 , -118.125],
           [ 
    [NiftiMasker.transform_single_imgs] Extracting region signals
    [NiftiMasker.transform_single_imgs] Cleaning extracted signals
    Graph-net classification accuracy : 74.4444%




Visualization of Graph-net weights
------------------------------------


.. code-block:: default

    from nilearn.plotting import plot_stat_map, show
    coef_img = decoder.coef_img_
    plot_stat_map(coef_img, background_img,
                  title="graph-net: accuracy %g%%" % accuracy,
                  cut_coords=(-52, -5), display_mode="yz")

    # Save the coefficients to a nifti file
    coef_img.to_filename('haxby_graph-net_weights.nii')





.. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_space_net_001.png
    :class: sphx-glr-single-img





Now Fit SpaceNet with a TV-l1 penalty
--------------------------------------


.. code-block:: default

    decoder = SpaceNetClassifier(memory="nilearn_cache", penalty='tv-l1')
    decoder.fit(X_train, y_train)
    y_pred = decoder.predict(X_test)
    accuracy = (y_pred == y_test).mean() * 100.
    print("TV-l1 classification accuracy : %g%%" % accuracy)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [NiftiMasker.fit] Loading data from Nifti1Image(
    shape=(40, 64, 64, 126),
    affine=array([[  -3.5  ,    0.   ,    0.   ,   68.25 ],
           [   0.   ,    3.75 ,    0.   , -118.125],
           [   0.   ,    0.   ,    3.75 , -118.125],
           [
    [NiftiMasker.fit] Computing the mask
    /home/emdupre/Desktop/open_source/nilearn/nilearn/_utils/cache_mixin.py:296: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.
      warnings.warn("memory_level is currently set to 0 but "
    [NiftiMasker.fit] Resampling mask
    [NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(
    shape=(40, 64, 64, 126),
    affine=array([[  -3.5  ,    0.   ,    0.   ,   68.25 ],
           [   0.   ,    3.75 ,    0.   , -118.125],
           [   0.   ,    0.   ,    3.75 , -118.125],
           [
    [NiftiMasker.transform_single_imgs] Extracting region signals
    [NiftiMasker.transform_single_imgs] Cleaning extracted signals
    /home/emdupre/Desktop/open_source/nilearn/nilearn/decoding/space_net.py:834: UserWarning: Brain mask is bigger than the volume of a standard human brain. This object is probably not tuned to be used on such data.
      self.screening_percentile, self.mask_img_, verbose=self.verbose)
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    .........[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s
    ..............................................................[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  4.4min finished
    Time Elapsed: 264.805 seconds, 4 minutes.
    [NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(
    shape=(40, 64, 64, 90),
    affine=array([[  -3.5  ,    0.   ,    0.   ,   68.25 ],
           [   0.   ,    3.75 ,    0.   , -118.125],
           [   0.   ,    0.   ,    3.75 , -118.125],
           [ 
    [NiftiMasker.transform_single_imgs] Extracting region signals
    [NiftiMasker.transform_single_imgs] Cleaning extracted signals
    TV-l1 classification accuracy : 72.2222%




Visualization of TV-L1 weights
-------------------------------


.. code-block:: default

    coef_img = decoder.coef_img_
    plot_stat_map(coef_img, background_img,
                  title="tv-l1: accuracy %g%%" % accuracy,
                  cut_coords=(-52, -5), display_mode="yz")

    # Save the coefficients to a nifti file
    coef_img.to_filename('haxby_tv-l1_weights.nii')
    show()





.. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_space_net_002.png
    :class: sphx-glr-single-img





We can see that the TV-l1 penalty is 3 times slower to converge and
gives the same prediction accuracy. However, it yields much
cleaner coefficient maps


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 5 minutes  59.744 seconds)


.. _sphx_glr_download_auto_examples_02_decoding_plot_haxby_space_net.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: https://mybinder.org/badge_logo.svg
      :target: https://mybinder.org/v2/gh/nilearn/nilearn.github.io/master?filepath=examples/auto_examples/02_decoding/plot_haxby_space_net.ipynb
      :width: 150 px


  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_haxby_space_net.py <plot_haxby_space_net.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_haxby_space_net.ipynb <plot_haxby_space_net.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
