
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Nilearn: Machine learning for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.4. Region Extraction for better brain parcellations" href="region_extraction.html" />
    <link rel="prev" title="3.2.3.1. Group-sparse covariance estimation" href="../developers/group_sparse_covariance.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000)
        $('.related-wrapper').css("position", "sticky")
        $('.related-wrapper').css("top", 0)
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative")
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight()
    var banner_width = $('#logo-banner').outerWidth()
    var width = $('.related-wrapper').css("height", $('.related').outerHeight())

    updateTopMenuPosition(banner_height, width)

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth()
        var menu_height = $('.related').outerHeight()
        $('.related').css("width", banner_width)
        $('.related-wrapper').css("height", menu_height)
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop()
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed")
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative")
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0
    current_section = 0
    $('a.internal').removeClass('active')
    for(i in sections) {
        if(sections[i] > pos) {
            break
        };
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        };
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active')
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight()
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0))
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop
    sections = {}
    url = document.URL.replace(/#.*$/, "")

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections)

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight()
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../index.html">
      <img src="../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="#">ICA</a></big>
    </li>
    <li>
      <a href="../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="region_extraction.html" title="3.4. Region Extraction for better brain parcellations"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../developers/group_sparse_covariance.html" title="3.2.3.1. Group-sparse covariance estimation"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="index.html" accesskey="U">3. Functional connectivity and resting state</a> &#187;</li> 
      </ul>
    </div>
</div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">3.3. Extracting resting-state networks: ICA and related</a><ul>
<li><a class="reference internal" href="#multi-subject-ica-canica">3.3.1. Multi-subject ICA: CanICA</a><ul>
<li><a class="reference internal" href="#data-preparation-retrieving-example-data">3.3.1.1. Data preparation: retrieving example data</a></li>
<li><a class="reference internal" href="#applying-canica">3.3.1.2. Applying CanICA</a></li>
<li><a class="reference internal" href="#visualizing-the-results">3.3.1.3. Visualizing the results</a></li>
</ul>
</li>
<li><a class="reference internal" href="#beyond-ica-dictionary-learning">3.3.2. Beyond ICA : Dictionary learning</a><ul>
<li><a class="reference internal" href="#applying-dictlearning">3.3.2.1. Applying DictLearning</a></li>
<li><a class="reference internal" href="#id1">3.3.2.2. Visualizing the results</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../developers/group_sparse_covariance.html"
                        title="previous chapter">3.2.3.1. Group-sparse covariance estimation</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="region_extraction.html"
                        title="next chapter">3.4. Region Extraction for better brain parcellations</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="extracting-resting-state-networks-ica-and-related">
<span id="extracting-rsn"></span><h1>3.3. Extracting resting-state networks: ICA and related<a class="headerlink" href="#extracting-resting-state-networks-ica-and-related" title="Permalink to this headline">¶</a></h1>
<div class="topic">
<p class="topic-title first"><strong>Page summary</strong></p>
<p>This page demonstrates the use of multi-subject Independent Component
Analysis (ICA) of resting-state fMRI data to extract brain networks in
an data-driven way. Here we use the ‘CanICA’ approach, that implements
a multivariate random effects model across subjects. A newer technique,
based on dictionary learning, is then described.</p>
</div>
<div class="section" id="multi-subject-ica-canica">
<h2>3.3.1. Multi-subject ICA: CanICA<a class="headerlink" href="#multi-subject-ica-canica" title="Permalink to this headline">¶</a></h2>
<div class="topic">
<p class="topic-title first"><strong>References</strong></p>
<ul class="simple">
<li>G. Varoquaux et al. “A group model for stable multi-subject ICA on
fMRI datasets”, <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S1053811910001618">NeuroImage Vol 51 (2010)</a>, p. 288-299</li>
</ul>
</div>
<div class="section" id="data-preparation-retrieving-example-data">
<h3>3.3.1.1. Data preparation: retrieving example data<a class="headerlink" href="#data-preparation-retrieving-example-data" title="Permalink to this headline">¶</a></h3>
<p>We will use sample data from the <a class="reference external" href="http://fcon_1000.projects.nitrc.org/indi/adhd200/">ADHD 200 resting-state dataset</a> has been
preprocessed using <a class="reference external" href="http://fcp-indi.github.io/">CPAC</a>. We use nilearn
functions to fetch data from Internet and get the filenames (<a class="reference internal" href="../manipulating_images/input_output.html#loading-data"><span class="std std-ref">more
on data loading</span></a>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="k">import</span> <span class="n">datasets</span>

<span class="n">adhd_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_adhd</span><span class="p">(</span><span class="n">n_subjects</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">func_filenames</span> <span class="o">=</span> <span class="n">adhd_dataset</span><span class="o">.</span><span class="n">func</span>  <span class="c1"># list of 4D nifti files for each subject</span>

<span class="c1"># print basic information on the dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;First functional nifti image (4D) is at: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
      <span class="n">func_filenames</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># 4D data</span>


</pre></div>
</div>
</div>
<div class="section" id="applying-canica">
<h3>3.3.1.2. Applying CanICA<a class="headerlink" href="#applying-canica" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../modules/generated/nilearn.decomposition.CanICA.html#nilearn.decomposition.CanICA" title="nilearn.decomposition.CanICA"><code class="xref py py-class docutils literal notranslate"><span class="pre">CanICA</span></code></a> is a ready-to-use object that can be applied to
multi-subject Nifti data, for instance presented as filenames, and will
perform a multi-subject ICA decomposition following the CanICA model.
As with every object in nilearn, we give its parameters at construction,
and then fit it on the data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># ---------------------------------</span>
<span class="kn">from</span> <span class="nn">nilearn.decomposition</span> <span class="k">import</span> <span class="n">CanICA</span>

<span class="n">canica</span> <span class="o">=</span> <span class="n">CanICA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">smoothing_fwhm</span><span class="o">=</span><span class="mf">6.</span><span class="p">,</span>
                <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;nilearn_cache&quot;</span><span class="p">,</span> <span class="n">memory_level</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="mf">3.</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">canica</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">func_filenames</span><span class="p">)</span>

<span class="c1"># Retrieve the independent components in brain space. Directly</span>
<span class="c1"># accesible through attribute `components_img_`. Note that this</span>
<span class="c1"># attribute is implemented from version 0.4.1. For older versions,</span>
<span class="c1"># see note section above for details.</span>
<span class="n">components_img</span> <span class="o">=</span> <span class="n">canica</span><span class="o">.</span><span class="n">components_img_</span>
<span class="c1"># components_img is a Nifti Image object, and can be saved to a file with</span>
<span class="c1"># the following line:</span>
<span class="n">components_img</span><span class="o">.</span><span class="n">to_filename</span><span class="p">(</span><span class="s1">&#39;canica_resting_state.nii.gz&#39;</span><span class="p">)</span>


</pre></div>
</div>
<p>The components estimated are found as the <cite>components_img_</cite> attribute
of the object. A 4D Nifti image.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <cite>components_img_</cite> attribute is implemented from version 0.4.1 which
is easy for visualization without any additional step to unmask to image.
For users who have older versions, components image can be done by
unmasking attribute <cite>components_</cite>. See <a class="reference internal" href="../manipulating_images/masker_objects.html#unmasking-step"><span class="std std-ref">section Inverse transform:
unmasking data</span></a>.</p>
</div>
</div>
<div class="section" id="visualizing-the-results">
<h3>3.3.1.3. Visualizing the results<a class="headerlink" href="#visualizing-the-results" title="Permalink to this headline">¶</a></h3>
<p>We can visualize the components as in the previous examples. The first plot
shows a map generated from all the components. Then we plot an axial cut for
each component separately.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># -----------------------------------------------------------------</span>
<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="k">import</span> <span class="n">plot_prob_atlas</span>

<span class="c1"># Plot all ICA components together</span>
<span class="n">plot_prob_atlas</span><span class="p">(</span><span class="n">components_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;All ICA components&#39;</span><span class="p">)</span>


</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/03_connectivity/plot_canica_resting_state.html"><img alt="../_images/sphx_glr_plot_canica_resting_state_0011.png" src="../_images/sphx_glr_plot_canica_resting_state_0011.png" /></a>
</div>
<p>Finally, we can plot the map for different ICA components separately:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># -----------------------------------------------------------</span>
<span class="kn">from</span> <span class="nn">nilearn.image</span> <span class="k">import</span> <span class="n">iter_img</span>
<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="k">import</span> <span class="n">plot_stat_map</span><span class="p">,</span> <span class="n">show</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cur_img</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">iter_img</span><span class="p">(</span><span class="n">components_img</span><span class="p">)):</span>
    <span class="n">plot_stat_map</span><span class="p">(</span><span class="n">cur_img</span><span class="p">,</span> <span class="n">display_mode</span><span class="o">=</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;IC </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span>
                  <span class="n">cut_coords</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p class="centered">
<strong><a class="reference internal" href="../_images/sphx_glr_plot_canica_resting_state_0031.png"><img alt="left_img" src="../_images/sphx_glr_plot_canica_resting_state_0031.png" style="width: 23%;" /></a> <a class="reference internal" href="../_images/sphx_glr_plot_canica_resting_state_0041.png"><img alt="right_img" src="../_images/sphx_glr_plot_canica_resting_state_0041.png" style="width: 23%;" /></a></strong></p><div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last">The full code can be found as an example:
<a class="reference internal" href="../auto_examples/03_connectivity/plot_canica_resting_state.html#sphx-glr-auto-examples-03-connectivity-plot-canica-resting-state-py"><span class="std std-ref">Group analysis of resting-state fMRI with ICA: CanICA</span></a></p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Note that as the ICA components are not ordered, the two components
displayed on your computer might not match those of the documentation. For
a fair representation, you should display all components and
investigate which one resemble those displayed above.</p>
</div>
</div>
</div>
<div class="section" id="beyond-ica-dictionary-learning">
<h2>3.3.2. Beyond ICA : Dictionary learning<a class="headerlink" href="#beyond-ica-dictionary-learning" title="Permalink to this headline">¶</a></h2>
<p>Recent work has shown that dictionary learning based techniques outperform
ICA in term of stability and constitutes a better first step in a statistical
analysis pipeline.
Dictionary learning in neuro-imaging seeks to extract a few representative
temporal elements along with their sparse spatial loadings, which constitute
good extracted maps.</p>
<div class="topic">
<p class="topic-title first"><strong>References</strong></p>
<ul class="simple">
<li>Arthur Mensch et al. <a class="reference external" href="https://hal.archives-ouvertes.fr/hal-01271033/">Compressed online dictionary learning for fast resting-state fMRI decomposition</a>,
ISBI 2016, Lecture Notes in Computer Science</li>
</ul>
</div>
<div class="section" id="applying-dictlearning">
<h3>3.3.2.1. Applying DictLearning<a class="headerlink" href="#applying-dictlearning" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../modules/generated/nilearn.decomposition.DictLearning.html#nilearn.decomposition.DictLearning" title="nilearn.decomposition.DictLearning"><code class="xref py py-class docutils literal notranslate"><span class="pre">DictLearning</span></code></a> is a ready-to-use class with the same interface as CanICA.
Sparsity of output map is controlled by a parameter alpha: using a
larger alpha yields sparser maps.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># --------------------</span>
<span class="c1"># </span>
<span class="c1"># We use as &quot;template&quot; as a strategy to compute the mask, as this leads</span>
<span class="c1"># to slightly faster and more reproducible results. However, the images</span>
<span class="c1"># need to be in MNI template space</span>
<span class="n">dict_learning</span> <span class="o">=</span> <span class="n">DictLearning</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span>
                             <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;nilearn_cache&quot;</span><span class="p">,</span> <span class="n">memory_level</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                             <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                             <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                             <span class="n">mask_strategy</span><span class="o">=</span><span class="s1">&#39;template&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>We can fit both estimators to compare them</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># --------------------</span>
<span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span><span class="n">dict_learning</span><span class="p">,</span> <span class="n">canica</span><span class="p">]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">{</span><span class="n">dict_learning</span><span class="p">:</span> <span class="s1">&#39;DictionaryLearning&#39;</span><span class="p">,</span> <span class="n">canica</span><span class="p">:</span> <span class="s1">&#39;CanICA&#39;</span><span class="p">}</span>
<span class="n">components_imgs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="n">estimators</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Example] Learning maps using </span><span class="si">%s</span><span class="s1"> model&#39;</span> <span class="o">%</span> <span class="n">names</span><span class="p">[</span><span class="n">estimator</span><span class="p">])</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">func_filenames</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Example] Saving results&#39;</span><span class="p">)</span>
    <span class="c1"># Grab extracted components umasked back to Nifti image.</span>
    <span class="c1"># Note: For older versions, less than 0.4.1. components_img_</span>
    <span class="c1"># is not implemented. See Note section above for details.</span>
    <span class="n">components_img</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">components_img_</span>
    <span class="n">components_img</span><span class="o">.</span><span class="n">to_filename</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_resting_state.nii.gz&#39;</span> <span class="o">%</span>
                               <span class="n">names</span><span class="p">[</span><span class="n">estimator</span><span class="p">])</span>
    <span class="n">components_imgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">components_img</span><span class="p">)</span>

</pre></div>
</div>
</div>
<div class="section" id="id1">
<h3>3.3.2.2. Visualizing the results<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>4D plotting offers an efficient way to compare both resulting outputs</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># ----------------------</span>
<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="k">import</span> <span class="p">(</span><span class="n">plot_prob_atlas</span><span class="p">,</span> <span class="n">find_xyz_cut_coords</span><span class="p">,</span> <span class="n">show</span><span class="p">,</span>
                              <span class="n">plot_stat_map</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">nilearn.image</span> <span class="k">import</span> <span class="n">index_img</span>

<span class="c1"># Selecting specific maps to display: maps were manually chosen to be similar</span>
<span class="n">indices</span> <span class="o">=</span> <span class="p">{</span><span class="n">dict_learning</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span> <span class="n">canica</span><span class="p">:</span> <span class="mi">33</span><span class="p">}</span>
<span class="c1"># We select relevant cut coordinates for displaying</span>
<span class="n">cut_component</span> <span class="o">=</span> <span class="n">index_img</span><span class="p">(</span><span class="n">components_imgs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">indices</span><span class="p">[</span><span class="n">dict_learning</span><span class="p">])</span>
<span class="n">cut_coords</span> <span class="o">=</span> <span class="n">find_xyz_cut_coords</span><span class="p">(</span><span class="n">cut_component</span><span class="p">)</span>
<span class="k">for</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">components</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">estimators</span><span class="p">,</span> <span class="n">components_imgs</span><span class="p">):</span>
    <span class="c1"># 4D plotting</span>
    <span class="n">plot_prob_atlas</span><span class="p">(</span><span class="n">components</span><span class="p">,</span> <span class="n">view_type</span><span class="o">=</span><span class="s2">&quot;filled_contours&quot;</span><span class="p">,</span>
                    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">names</span><span class="p">[</span><span class="n">estimator</span><span class="p">],</span>
                    <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># 3D plotting</span>
    <span class="n">plot_stat_map</span><span class="p">(</span><span class="n">index_img</span><span class="p">(</span><span class="n">components</span><span class="p">,</span> <span class="n">indices</span><span class="p">[</span><span class="n">estimator</span><span class="p">]),</span>
                  <span class="n">title</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">names</span><span class="p">[</span><span class="n">estimator</span><span class="p">],</span>
                  <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/03_connectivity/plot_compare_resting_state_decomposition.html"><img alt="left_img_decomp" src="../_images/sphx_glr_plot_compare_resting_state_decomposition_0011.png" style="width: 50%;" /></a> <a class="reference external" href="../auto_examples/03_connectivity/plot_compare_resting_state_decomposition.html"><img alt="right_img_decomp" src="../_images/sphx_glr_plot_compare_resting_state_decomposition_0031.png" style="width: 50%;" /></a></strong></p><p class="centered">
<strong><a class="reference external" href="../auto_examples/03_connectivity/plot_compare_resting_state_decomposition.html"><img alt="left_img_decomp_single" src="../_images/sphx_glr_plot_compare_resting_state_decomposition_0021.png" style="width: 50%;" /></a> <a class="reference external" href="../auto_examples/03_connectivity/plot_compare_resting_state_decomposition.html"><img alt="right_img_decomp_single" src="../_images/sphx_glr_plot_compare_resting_state_decomposition_0041.png" style="width: 50%;" /></a></strong></p><p>Maps obtained with dictionary leaning are often easier to exploit as they are
less noisy than ICA maps, with blobs usually better defined. Typically,
<em>smoothing can be lower than when doing ICA</em>.
While dictionary learning computation time is comparable to CanICA, obtained
atlases have been shown to outperform ICA in a variety of
classification tasks.</p>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last">The full code can be found as an example:
<a class="reference internal" href="../auto_examples/03_connectivity/plot_compare_resting_state_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-resting-state-decomposition-py"><span class="std std-ref">Dictionary Learning and ICA for doing group analysis of resting-state fMRI</span></a></p>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2015.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.8.2.
        <span style="padding-left: 5ex;">
          <a href="../_sources/connectivity/resting_state_networks.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>