{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nGroup analysis of resting-state fMRI with ICA: CanICA\n=====================================================\n\nAn example applying CanICA to resting-state data. This example applies it\nto 30 subjects of the ADHD200 datasets. Then it plots a map with all the\ncomponents together and an axial cut for each of the components separately.\n\nCanICA is an ICA method for group-level analysis of fMRI data. Compared\nto other strategies, it brings a well-controlled group model, as well as a\nthresholding algorithm controlling for specificity and sensitivity with\nan explicit model of the signal. The reference papers are:\n\n    * G. Varoquaux et al. \"A group model for stable multi-subject ICA on\n      fMRI datasets\", NeuroImage Vol 51 (2010), p. 288-299\n\n    * G. Varoquaux et al. \"ICA-based sparse features recovery from fMRI\n      datasets\", IEEE ISBI 2010, p. 1177\n\nPre-prints for both papers are available on hal\n(http://hal.archives-ouvertes.fr)\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The use of the attribute `components_img_` from decomposition\n    estimators is implemented from version 0.4.1.\n    For older versions, unmask the deprecated attribute `components_`\n    to get the components image using attribute `masker_` embedded in\n    estimator.\n    See the `section Inverse transform: unmasking data <unmasking_step>`.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we load the ADHD200 data\n-------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import datasets\n\nadhd_dataset = datasets.fetch_adhd(n_subjects=30)\nfunc_filenames = adhd_dataset.func  # list of 4D nifti files for each subject\n\n# print basic information on the dataset\nprint('First functional nifti image (4D) is at: %s' %\n      func_filenames[0])  # 4D data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we apply CanICA on the data\n---------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.decomposition import CanICA\n\ncanica = CanICA(n_components=20, smoothing_fwhm=6.,\n                memory=\"nilearn_cache\", memory_level=2,\n                threshold=3., verbose=10, random_state=0)\ncanica.fit(func_filenames)\n\n# Retrieve the independent components in brain space. Directly\n# accesible through attribute `components_img_`. Note that this\n# attribute is implemented from version 0.4.1. For older versions,\n# see note section above for details.\ncomponents_img = canica.components_img_\n# components_img is a Nifti Image object, and can be saved to a file with\n# the following line:\ncomponents_img.to_filename('canica_resting_state.nii.gz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To visualize we plot the outline of all components on one figure\n-----------------------------------------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_prob_atlas\n\n# Plot all ICA components together\nplot_prob_atlas(components_img, title='All ICA components')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we plot the map for each ICA component separately\n-----------------------------------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.image import iter_img\nfrom nilearn.plotting import plot_stat_map, show\n\nfor i, cur_img in enumerate(iter_img(components_img)):\n    plot_stat_map(cur_img, display_mode=\"z\", title=\"IC %d\" % i,\n                  cut_coords=1, colorbar=False)\n\nshow()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}